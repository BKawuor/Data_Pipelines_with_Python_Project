# -*- coding: utf-8 -*-
"""Data_Pipelines_with_Python_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SV_NO6tw8qCkNKGLQb3vcdFVIIl8FItU

# Data Pipelines with Python Project
## 1. Defining the Question
a) Specifying the Data Analysis Question


As a Data professional, you are required to create an automated data pipeline that can extract billing data from multiple sources and transform it into a structured format for efficient analysis and revenue reporting.

## b) Defining the Metric for Success

Measure of success will be measured by atttempting to have the data pipeline do the following:

Extract the data: Use Python to read the CSV files and extract the data.
Clean the data: Perform data cleaning on the extracted data to remove any missing
values and outliers. For example, you can replace missing values with an appropriate value or remove them altogether. 3. Transform the data: Apply any necessary transformations on the data, such as data type conversion, data aggregation, and data filtering, to prepare the data for analysis. 4. Merge the datasets: Join the different datasets into a single dataset that can be used for analysis. 5. Load the data: Load the transformed data into a database or a file, such as a CSV file, that can be easily analyzed. 6. Automate the process: Automate the data pipeline by scheduling it to run at a specific time, such as daily or weekly so that it can update the analysis data automatically. 7. Test the pipeline: Test the data pipeline to ensure it produces the correct results. This can be done by comparing the results with the expected output or using a test dataset. 8. Optimize the pipeline: Optimize the data pipeline to improve performance and reduce errors. This can be done by optimizing the code, parallel processing, and reducing the data size. 9. Monitor the pipeline: Monitor the data pipeline to ensure that it runs smoothly and that there are no errors or issues.

## c) Understanding the context

Telecom companies often have to extract billing data from multiple CSV files generated from various systems and transform it into a structured format for analysis and revenue reporting. This process can be time-consuming, error-prone, and hinder decision-making. Manually analyzing and reconciling billing data from different sources is a tedious task and often leads to delays in generating revenue reports. Thus, there is a need for an automated data pipeline that can extract billing data from multiple sources and transform it into a structured format for efficient analysis and revenue reporting.

Datasets

Here are three sample datasets (https://bit.ly/416WE1X) with billing data that can be joined. The datasets contain some missing values and outliers: Dataset 1:

● Customer ID (numeric)

● Date of purchase (MM/DD/YYYY)

● Total amount billed (numeric)

● Payment status (categorical - paid, overdue, disputed)

● Payment method (categorical - credit card, bank transfer, e-wallet) ● Promo code (text)

● Country of purchase (categorical)

Dataset 2:

● Customer ID (numeric)

● Date of payment (MM/DD/YYYY)

● Amount paid (numeric)

● Payment method (categorical - credit card, bank transfer, e-wallet)

● Payment status (categorical - paid, overdue, disputed)

● Late payment fee (numeric)

● Country of payment (categorical)

Dataset 3:

● Customer ID (numeric)

● Date of refund (MM/DD/YYYY)

● Refund amount (numeric)

● Reason for refund (text)

● Country of refund (categorical)

Notes:

The datasets can be joined using Customer ID, Date of purchase/payment/refund, and country of purchase/payment/refund as keys.
The datasets may contain missing values and outliers for some fields, such as the total amount billed or refund amount.
The payment status may be missing or incomplete for some of the transactions.
The promo code field may be empty for some of the purchases.
The reason for the refund may be missing for some of the refund transactions.

## d) Recording the Experimental Design

Data Importation.

Data Cleaning.

Data Tranformation.

Run the pipeline.

## e) Data Relevance

The dataset used is indisputable, since it is available publicly online and anyone can use the same data to challenge any conclusion arrived at on the analysis performed herein.

## 2. Data Importation
"""

# install pandas
import pandas as pd
import os

# Define the names of the CSV files
ds1 = 'dataset1.csv'
ds2 = 'dataset2.csv'
ds3 = 'dataset3.csv'

# Load the datasets
dataset_1 = pd.read_csv(ds1)
dataset_2 = pd.read_csv(ds2)
dataset_3 = pd.read_csv(ds3)

dataset_1.columns

dataset_2.columns

dataset_3.columns

"""# 3. Data Cleaning"""

# Data Cleaning
# Replace missing values in Total amount billed with 0
dataset_1['total_amount_billed'].fillna(value=0, inplace=True)
# Replace missing values in Refund amount with 0
dataset_3['refund_amount'].fillna(value=0, inplace=True)

"""# Merging Datasets"""

# Merging datasets

# Renaming  columns
dataset1 = dataset_1.rename(columns={"date_of_purchase": "date", "country_of_purchase": "country"})
dataset2 = dataset_2.rename(columns={"date_of_payment": "date", "country_of_payment": "country"})
dataset3 = dataset_3.rename(columns={"date_of_refund": "date", "country_of_refund": "country"})


merged_ds = pd.merge(dataset1, dataset2, on=['customer_id','date','country'],
                          how='outer', suffixes = ('_purchase', '_payment'))
merged_ds = pd.merge(merged_ds, dataset3, on=['customer_id','date','country'],
                          how='outer', suffixes = ('_pp', '_refund'))

merged_ds.head()

merged_ds.columns

# Further Data cleaning
# Replace missing values in Amount paid with 0
merged_ds['amount_paid'].fillna(value=0, inplace=True)
# Replace missing values in Late payment fee with 0
merged_ds['late_payment_fee'].fillna(value=0, inplace=True)
# Replace missing values in Promo code with 'NA'
merged_ds['promo_code'].fillna(value='NA', inplace=True)
# Replace missing values in Reason for refund with 'NA'
merged_ds['reason_for_refund'].fillna(value='NA', inplace=True

"""# 4. Data transformation"""

# Transform the data
merged_ds['date'] = pd.to_datetime(merged_ds['date'], format='%m/%d/%Y')

# Convert Total amount billed, Amount paid, Refund amount, and Late payment fee to float
merged_ds['total_amount_billed'] = pd.to_numeric(merged_ds['total_amount_billed'], errors='coerce')
merged_ds['amount_paid'] = pd.to_numeric(merged_ds['amount_paid'], errors='coerce')
merged_ds['refund_amount'] = pd.to_numeric(merged_ds['refund_amount'], errors='coerce')
merged_ds['late_payment_fee'] = pd.to_numeric(merged_ds['late_payment_fee'], errors='coerce')

# Aggregate the data
# Compute the difference between Total amount billed and Amount paid as Balance due
merged_ds['balance_due'] = merged_ds['total_amount_billed'] - merged_ds['amount_paid']

# Filter the data
# Keep only the rows where Balance due is greater than 0
merged_ds = merged_ds[merged_ds['balance_due'] > 0]

"""# 5. Save final pipeline output"""

# Output the data to a CSV file
merged_ds.to_csv('billing_data.csv', index=False)

"""# a). Did we have the right data?
Yes

# b). Do we need other data to answer our question?
The data provided was enough for the question

# c). Did we have the right question?
We did
"""